{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e403412d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927dbde5",
   "metadata": {},
   "source": [
    "In keras, you use the word dense to define a layer of connected neurons. There's only one dense here. So there's only one layer and there's only one unit in it, so it's a single neuron.\n",
    "\n",
    "Successive layers are defined in sequence, hence the word sequential. \n",
    "\n",
    "You define the shape of what's input to the neural network in the first and in this case the only layer, and you can see that our input shape is super simple. It's just one value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13b3447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([keras.layers.Dense(units=1,\n",
    "                                            input_shape=[1])])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4308c9c",
   "metadata": {},
   "source": [
    "The neural network has no idea of the relationship between X and Y, so it makes a guess. Say it guesses Y equals 10X minus 10. It will then use the data that it knows about, that's the set of Xs and Ys that we've already seen to measure how good or how bad its guess was. The loss function measures this and then gives the data to the optimizer which figures out the next guess. \n",
    "\n",
    "As the guesses get better and better, an accuracy approaches 100 percent, the term convergence is used. In this case, the loss is mean squared error and the optimizer is SGD which stands for stochastic gradient descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5740619",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8216e078",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs= np.array([-1.0,0.0,1.0,2.0,3.0,4.0],dtype=float)\n",
    "ys= np.array([-3.0,-1.0,1.0,3.0,5.0,7.0],dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9b9ce5",
   "metadata": {},
   "source": [
    "The epochs equals 10 value means that it will go through the training loop 10 times. This training loop is what we described earlier. Make a guess, measure how good or how bad the guesses with the loss function, then use the optimizer and the data to make another guess and repeat this. When the model has finished training, it will then give you back values using the predict method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5626408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.5764\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5643\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5525\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5410\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5298\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5188\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.5081\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4976\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4873\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.4773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2f24b991748>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xs,ys,epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc34d30",
   "metadata": {},
   "source": [
    "Ultimately there are two main reasons. The first is that you trained it using very little data. There's only six points. Those six points are linear but there's no guarantee that for every X, the relationship will be Y equals 2X minus 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c681709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 82ms/step\n",
      "[[16.940388]\n",
      " [33.97659 ]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([10.0,20.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b072afc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
